{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##setting"
      ],
      "metadata": {
        "id": "M-75f22n11Af"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kDrgMzfmSUa",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title need\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip3 install -U xformers --index-url https://download.pytorch.org/whl/cu126\n",
        "!pip uninstall -y compel\n",
        "!pip install compel==2.2.1\n",
        "\n",
        "url=\"https://raw.githubusercontent.com/MokubaAttack/scripts/refs/heads/main/mokuba_colab/mokuba_colab2.py\"\n",
        "path=\"mokuba_colab.py\"\n",
        "import requests\n",
        "urlData = requests.get(url).content\n",
        "\n",
        "with open(path ,mode='wb') as f:\n",
        "  f.write(urlData)\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output(True)\n",
        "print(\"fin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##checkpoint"
      ],
      "metadata": {
        "id": "Mp-m2DBF19iV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###civitai"
      ],
      "metadata": {
        "id": "cH5N_2Co2EIN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DNDuVjFb1xy",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title get\n",
        "base_air=None# @param {\"type\":\"integer\"}\n",
        "\n",
        "from google.colab import userdata\n",
        "import requests\n",
        "import os\n",
        "import json\n",
        "\n",
        "ca_token=userdata.get('civitai')\n",
        "base_url = \"https://civitai.com/api/download/models/\"+str(base_air)+\"?type=Model&format=SafeTensor&token=\"+str(ca_token)\n",
        "base_path=\"base.safetensors\"\n",
        "with open(base_path, \"wb\") as fh:\n",
        "    data = requests.get(base_url,stream=True)\n",
        "    limit=1024*1024*1024*1024\n",
        "    dummy_data=b\"\"\n",
        "    step1=True\n",
        "    step2=True\n",
        "    for chunk in data.iter_content(chunk_size=1024*1024):\n",
        "        if step2:\n",
        "            dummy_data=dummy_data+chunk\n",
        "        else:\n",
        "            fh.write(chunk)\n",
        "        if len(dummy_data)>8 and step1:\n",
        "            limit=int.from_bytes(dummy_data[:8],byteorder=\"little\")\n",
        "            dummy_data=dummy_data[8:]\n",
        "            step1=False\n",
        "        if len(dummy_data)>limit and step2:\n",
        "            head=dummy_data[:limit].decode()\n",
        "            head_dict=json.loads(head)\n",
        "            meta_dict={}\n",
        "            meta_dict[\"id\"]=str(base_air)\n",
        "            head_dict[\"__metadata__\"]=meta_dict\n",
        "            head=str(head_dict)\n",
        "            head=head.replace(\"'\",'\"')\n",
        "            b_data=head.encode()\n",
        "            b_len=len(b_data).to_bytes(8,byteorder=\"little\")\n",
        "            fh.write(b_len)\n",
        "            fh.write(b_data)\n",
        "            dummy_data=dummy_data[limit:]\n",
        "            fh.write(dummy_data)\n",
        "            step2=False\n",
        "\n",
        "print(str(base_air))\n",
        "from IPython import get_ipython\n",
        "get_ipython().magic(\"reset -sf\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you input CivitAi's Version ID,  \n",
        "ckpt data is downloaded by the name of \"base.safetensors\"."
      ],
      "metadata": {
        "id": "D6h2Z3uFTybB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##lora"
      ],
      "metadata": {
        "id": "HdW7Yxul2-RJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyrZ-WESLy4q",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title lora1\n",
        "lora_air=None# @param {\"type\":\"integer\"}\n",
        "\n",
        "from google.colab import userdata\n",
        "from requests import get\n",
        "from safetensors.torch import load_file,save_file\n",
        "ca_token=userdata.get('civitai')\n",
        "lora_url = \"https://civitai.com/api/download/models/\"+str(lora_air)+\"?type=Model&format=SafeTensor&token=\"+str(ca_token)\n",
        "lora_path=\"lora1.safetensors\"\n",
        "with open(lora_path, \"wb\") as fh:\n",
        "  data = get(lora_url, stream=True)\n",
        "  for chunk in data.iter_content(chunk_size=8192):\n",
        "    fh.write(chunk)\n",
        "\n",
        "unnecessary=[\n",
        "    \"lora_unet_out_2.alpha\",\n",
        "    \"lora_unet_out_2.lora_down.weight\",\n",
        "    \"lora_unet_out_2.lora_up.weight\",\n",
        "    \"lora_unet_input_blocks_0_0.alpha\",\n",
        "    \"lora_unet_input_blocks_0_0.lora_down.weight\",\n",
        "    \"lora_unet_input_blocks_0_0.lora_up.weight\",\n",
        "    \"lora_unet_label_emb_0_0.alpha\",\n",
        "    \"lora_unet_label_emb_0_0.lora_down.weight\",\n",
        "    \"lora_unet_label_emb_0_0.lora_up.weight\",\n",
        "    \"lora_unet_label_emb_0_2.alpha\",\n",
        "    \"lora_unet_label_emb_0_2.lora_down.weight\",\n",
        "    \"lora_unet_label_emb_0_2.lora_up.weight\",\n",
        "    \"lora_unet_time_embed_0.alpha\",\n",
        "    \"lora_unet_time_embed_0.lora_down.weight\",\n",
        "    \"lora_unet_time_embed_0.lora_up.weight\",\n",
        "    \"lora_unet_time_embed_2.alpha\",\n",
        "    \"lora_unet_time_embed_2.lora_down.weight\",\n",
        "    \"lora_unet_time_embed_2.lora_up.weight\"\n",
        "   ]\n",
        "\n",
        "state_dict = load_file(lora_path)\n",
        "ks=[]\n",
        "ws=[]\n",
        "for k, w in state_dict.items():\n",
        "    if not(k in unnecessary):\n",
        "        ks.append(k)\n",
        "        ws.append(w)\n",
        "l=len(ks)\n",
        "state_dict={}\n",
        "for i in range(l):\n",
        "    state_dict[ks[i]]=ws[i]\n",
        "meta_dict={}\n",
        "meta_dict[\"id\"]=str([lora_air])\n",
        "meta_dict[\"weight\"]=str([1])\n",
        "save_file(state_dict,lora_path,metadata=meta_dict)\n",
        "print(str(lora_air))\n",
        "from IPython import get_ipython\n",
        "get_ipython().magic(\"reset -sf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you input CivitAi's Version ID,  \n",
        "lora data is downloaded by the name of \"lora1.safetensors\"."
      ],
      "metadata": {
        "id": "3jMZcwkXUk-E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNZxcEclG18O",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title lora2\n",
        "lora_air=None# @param {\"type\":\"integer\"}\n",
        "\n",
        "from google.colab import userdata\n",
        "from requests import get\n",
        "from safetensors.torch import load_file,save_file\n",
        "ca_token=userdata.get('civitai')\n",
        "lora_url = \"https://civitai.com/api/download/models/\"+str(lora_air)+\"?type=Model&format=SafeTensor&token=\"+str(ca_token)\n",
        "lora_path=\"lora2.safetensors\"\n",
        "with open(lora_path, \"wb\") as fh:\n",
        "  data = get(lora_url, stream=True)\n",
        "  for chunk in data.iter_content(chunk_size=8192):\n",
        "    fh.write(chunk)\n",
        "\n",
        "unnecessary=[\n",
        "    \"lora_unet_out_2.alpha\",\n",
        "    \"lora_unet_out_2.lora_down.weight\",\n",
        "    \"lora_unet_out_2.lora_up.weight\",\n",
        "    \"lora_unet_input_blocks_0_0.alpha\",\n",
        "    \"lora_unet_input_blocks_0_0.lora_down.weight\",\n",
        "    \"lora_unet_input_blocks_0_0.lora_up.weight\",\n",
        "    \"lora_unet_label_emb_0_0.alpha\",\n",
        "    \"lora_unet_label_emb_0_0.lora_down.weight\",\n",
        "    \"lora_unet_label_emb_0_0.lora_up.weight\",\n",
        "    \"lora_unet_label_emb_0_2.alpha\",\n",
        "    \"lora_unet_label_emb_0_2.lora_down.weight\",\n",
        "    \"lora_unet_label_emb_0_2.lora_up.weight\",\n",
        "    \"lora_unet_time_embed_0.alpha\",\n",
        "    \"lora_unet_time_embed_0.lora_down.weight\",\n",
        "    \"lora_unet_time_embed_0.lora_up.weight\",\n",
        "    \"lora_unet_time_embed_2.alpha\",\n",
        "    \"lora_unet_time_embed_2.lora_down.weight\",\n",
        "    \"lora_unet_time_embed_2.lora_up.weight\"\n",
        "   ]\n",
        "\n",
        "state_dict = load_file(lora_path)\n",
        "ks=[]\n",
        "ws=[]\n",
        "for k, w in state_dict.items():\n",
        "    if not(k in unnecessary):\n",
        "        ks.append(k)\n",
        "        ws.append(w)\n",
        "l=len(ks)\n",
        "state_dict={}\n",
        "for i in range(l):\n",
        "    state_dict[ks[i]]=ws[i]\n",
        "meta_dict={}\n",
        "meta_dict[\"id\"]=str([lora_air])\n",
        "meta_dict[\"weight\"]=str([1])\n",
        "save_file(state_dict,lora_path,metadata=meta_dict)\n",
        "print(str(lora_air))\n",
        "from IPython import get_ipython\n",
        "get_ipython().magic(\"reset -sf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you input CivitAi's Version ID,  \n",
        "lora data is downloaded by the name of \"lora2.safetensors\"."
      ],
      "metadata": {
        "id": "YiHJAOCQUqhY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILet7SIaoNck",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title lora3\n",
        "lora_air=None# @param {\"type\":\"integer\"}\n",
        "\n",
        "from google.colab import userdata\n",
        "from requests import get\n",
        "from safetensors.torch import load_file,save_file\n",
        "ca_token=userdata.get('civitai')\n",
        "lora_url = \"https://civitai.com/api/download/models/\"+str(lora_air)+\"?type=Model&format=SafeTensor&token=\"+str(ca_token)\n",
        "lora_path=\"lora3.safetensors\"\n",
        "with open(lora_path, \"wb\") as fh:\n",
        "  data = get(lora_url, stream=True)\n",
        "  for chunk in data.iter_content(chunk_size=8192):\n",
        "    fh.write(chunk)\n",
        "\n",
        "unnecessary=[\n",
        "    \"lora_unet_out_2.alpha\",\n",
        "    \"lora_unet_out_2.lora_down.weight\",\n",
        "    \"lora_unet_out_2.lora_up.weight\",\n",
        "    \"lora_unet_input_blocks_0_0.alpha\",\n",
        "    \"lora_unet_input_blocks_0_0.lora_down.weight\",\n",
        "    \"lora_unet_input_blocks_0_0.lora_up.weight\",\n",
        "    \"lora_unet_label_emb_0_0.alpha\",\n",
        "    \"lora_unet_label_emb_0_0.lora_down.weight\",\n",
        "    \"lora_unet_label_emb_0_0.lora_up.weight\",\n",
        "    \"lora_unet_label_emb_0_2.alpha\",\n",
        "    \"lora_unet_label_emb_0_2.lora_down.weight\",\n",
        "    \"lora_unet_label_emb_0_2.lora_up.weight\",\n",
        "    \"lora_unet_time_embed_0.alpha\",\n",
        "    \"lora_unet_time_embed_0.lora_down.weight\",\n",
        "    \"lora_unet_time_embed_0.lora_up.weight\",\n",
        "    \"lora_unet_time_embed_2.alpha\",\n",
        "    \"lora_unet_time_embed_2.lora_down.weight\",\n",
        "    \"lora_unet_time_embed_2.lora_up.weight\"\n",
        "   ]\n",
        "\n",
        "state_dict = load_file(lora_path)\n",
        "ks=[]\n",
        "ws=[]\n",
        "for k, w in state_dict.items():\n",
        "    if not(k in unnecessary):\n",
        "        ks.append(k)\n",
        "        ws.append(w)\n",
        "l=len(ks)\n",
        "state_dict={}\n",
        "for i in range(l):\n",
        "    state_dict[ks[i]]=ws[i]\n",
        "meta_dict={}\n",
        "meta_dict[\"id\"]=str([lora_air])\n",
        "meta_dict[\"weight\"]=str([1])\n",
        "save_file(state_dict,lora_path,metadata=meta_dict)\n",
        "print(str(lora_air))\n",
        "from IPython import get_ipython\n",
        "get_ipython().magic(\"reset -sf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you input CivitAi's Version ID,  \n",
        "lora data is downloaded by the name of \"lora3.safetensors\"."
      ],
      "metadata": {
        "id": "Ks7_-AT2VE9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title file downloader\n",
        "ver_id=None # @param {\"type\":\"integer\"}\n",
        "\n",
        "from google.colab import userdata\n",
        "from requests import get\n",
        "from safetensors.torch import load_file,save_file\n",
        "ca_token=userdata.get('civitai')\n",
        "lora_url = \"https://civitai.com/api/download/models/\"+str(ver_id)+\"?type=Model&format=SafeTensor&token=\"+str(ca_token)\n",
        "lora_path=str(ver_id)+\".safetensors\"\n",
        "with open(lora_path, \"wb\") as fh:\n",
        "  data = get(lora_url, stream=True)\n",
        "  for chunk in data.iter_content(chunk_size=8192):\n",
        "    fh.write(chunk)\n",
        "\n",
        "unnecessary=[\n",
        "    \"lora_unet_out_2.alpha\",\n",
        "    \"lora_unet_out_2.lora_down.weight\",\n",
        "    \"lora_unet_out_2.lora_up.weight\",\n",
        "    \"lora_unet_input_blocks_0_0.alpha\",\n",
        "    \"lora_unet_input_blocks_0_0.lora_down.weight\",\n",
        "    \"lora_unet_input_blocks_0_0.lora_up.weight\",\n",
        "    \"lora_unet_label_emb_0_0.alpha\",\n",
        "    \"lora_unet_label_emb_0_0.lora_down.weight\",\n",
        "    \"lora_unet_label_emb_0_0.lora_up.weight\",\n",
        "    \"lora_unet_label_emb_0_2.alpha\",\n",
        "    \"lora_unet_label_emb_0_2.lora_down.weight\",\n",
        "    \"lora_unet_label_emb_0_2.lora_up.weight\",\n",
        "    \"lora_unet_time_embed_0.alpha\",\n",
        "    \"lora_unet_time_embed_0.lora_down.weight\",\n",
        "    \"lora_unet_time_embed_0.lora_up.weight\",\n",
        "    \"lora_unet_time_embed_2.alpha\",\n",
        "    \"lora_unet_time_embed_2.lora_down.weight\",\n",
        "    \"lora_unet_time_embed_2.lora_up.weight\"\n",
        "   ]\n",
        "\n",
        "state_dict = load_file(lora_path)\n",
        "ks=[]\n",
        "ws=[]\n",
        "for k, w in state_dict.items():\n",
        "    if not(k in unnecessary):\n",
        "        ks.append(k)\n",
        "        ws.append(w)\n",
        "l=len(ks)\n",
        "state_dict={}\n",
        "for i in range(l):\n",
        "    state_dict[ks[i]]=ws[i]\n",
        "meta_dict={}\n",
        "meta_dict[\"id\"]=str(ver_air)\n",
        "meta_dict[\"weight\"]=str(1)\n",
        "save_file(state_dict,lora_path,metadata=meta_dict)\n",
        "print(str(ver_air))\n",
        "from IPython import get_ipython\n",
        "get_ipython().magic(\"reset -sf\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uM_d7DroVf2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you input CivitAi's Version ID,  \n",
        "data is downloaded by the name of \"(ver_id).safetensors\"."
      ],
      "metadata": {
        "id": "zuTV0Y6sW2PI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## run"
      ],
      "metadata": {
        "id": "54dAGlTe3kPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title text2image\n",
        "#@markdown ##diffusers type\n",
        "dt=\"2:illustrious\" #@param [\"1:pony\", \"2:illustrious\", \"3:sdxl1.0\",\"4:sd1.5\"] {allow-input: true}\n",
        "dt=int(dt.split(\":\")[0])\n",
        "#@markdown ##ckpt file\n",
        "base_safe=\"ckpt.safetensors\" #@param {type:\"string\"}\n",
        "#@markdown ##vae file\n",
        "vae_safe=\"vae.safetensors\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ##lora files\n",
        "loras=\"lora1, lora2\" #@param {type:\"string\"}\n",
        "if loras==\"\":\n",
        "  loras=[]\n",
        "else:\n",
        "  loras=loras.split(\",\")\n",
        "#@markdown ##lora weights\n",
        "lora_weights=\"1, 1\" #@param {type:\"string\"}\n",
        "if lora_weights==\"\":\n",
        "  lora_weights=[]\n",
        "else:\n",
        "  lora_weights=lora_weights.split(\",\")\n",
        "  for i in range(len(lora_weights)):\n",
        "    lora_weights[i]=float(lora_weights[i])\n",
        "\n",
        "#@markdown ##positive embedding files\n",
        "pos_emb=\"pos.safetensors\" #@param {type:\"string\"}\n",
        "#@markdown ##negative embedding files\n",
        "neg_emb=\"neg.safetensors, hand.safetensors\" #@param {type:\"string\"}\n",
        "if pos_emb==\"\":\n",
        "  pos_emb=[]\n",
        "else:\n",
        "  pos_emb=pos_emb.split(\",\")\n",
        "if neg_emb==\"\":\n",
        "  neg_emb=[]\n",
        "else:\n",
        "  neg_emb=neg_emb.split(\",\")\n",
        "\n",
        "#@markdown ##prompt\n",
        "prompt = \"\" #@param {type:\"string\"}\n",
        "#@markdown ##negative prompt\n",
        "n_prompt = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ##output size\n",
        "t=\"vl:large\" #@param [\"v:vertically long\", \"s:square\", \"h:horizontally long\",\"vl:large\",\"sl:large\",\"hl:large\"] {allow-input: true}\n",
        "t=t.split(\":\")[0]\n",
        "#@markdown ##program type\n",
        "prog_ver=\"2:mokuba.fix\" #@param [\"0:nomal\", \"1:hires.fix\", \"2:mokuba.fix\"] {allow-input: true}\n",
        "prog_ver=int(prog_ver.split(\":\")[0])\n",
        "\n",
        "#@markdown ##number of output image\n",
        "pic_number=10# @param {\"type\":\"integer\"}\n",
        "#@markdown ##guidance_scale\n",
        "gs=7# @param {\"type\":\"number\"}\n",
        "#@markdown ##num_inference_steps\n",
        "step=25# @param {\"type\":\"integer\"}\n",
        "#@markdown ##first num_inference_steps\n",
        "f_step=30# @param {\"type\":\"integer\"}\n",
        "#@markdown ##denoising_strength\n",
        "ss=0.5# @param {\"type\":\"number\"}\n",
        "#@markdown ##clip_skip\n",
        "cs=2# @param {\"type\":\"integer\"}\n",
        "\n",
        "#@markdown ##seed\n",
        "seed=\"0\"# @param {\"type\":\"string\"}\n",
        "if \",\" in seed:\n",
        "  seed=seed.split(\",\")\n",
        "\n",
        "#@markdown ##interpolation method\n",
        "Interpolation=\"1:NEAREST\" #@param [\"1:NEAREST\",\"2:BOX\",\"3:BILINEAR\",\"4:HAMMING\",\"5:BICUBIC\",\"6:LANCZOS\"] {allow-input: true}\n",
        "Interpolation=int(Interpolation.split(\":\")[0])\n",
        "#@markdown ##Scheduler\n",
        "sample=\"DDIM\" #@param [\"Euler a\",\"Euler\",\"LMS\",\"Heun\", \"DPM2\",\"DPM2 a\",\"DPM++ 2M\",\"DPM++ SDE\",\"DPM++ 2M SDE\",\"DPM++ 3M SDE\",\"LMS Karras\",\"DPM2 Karras\",\"DPM2 a Karras\",\"DPM++ 2M Karras\",\"DPM++ SDE Karras\",\"DPM++ 2M SDE Karras\",\"DPM++ 3M SDE Karras\",\"DPM++ 3M SDE Exponential\",\"DDIM\",\"PLMS\",\"UniPC\",\"LCM\"] {allow-input: true}\n",
        "\n",
        "#@markdown ##Output folder\n",
        "out_folder=\"\"#@param {type:\"string\"}\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import mokuba_colab\n",
        "\n",
        "i=1\n",
        "while True:\n",
        "  if not(os.path.exists(out_folder+\"/\"+str(i))):\n",
        "    out_folder=out_folder+\"/\"+str(i)\n",
        "    os.makedirs(out_folder)\n",
        "    break\n",
        "  else:\n",
        "    file_paths = glob.glob(out_folder+\"/\"+str(i)+'/*.png')\n",
        "    if file_paths==[]:\n",
        "      shutil.rmtree(out_folder+\"/\"+str(i))\n",
        "      out_folder=out_folder+\"/\"+str(i)\n",
        "      os.makedirs(out_folder)\n",
        "      break\n",
        "  i=i+1\n",
        "\n",
        "if dt==4:\n",
        "  if v==\"\":\n",
        "    vae_safe=\"None.txt\"\n",
        "  seeds=mokuba_colab.text2image15( loras, lora_weights, prompt, n_prompt, t, prog_ver, pic_number, gs, f_step, step, ss, cs, Interpolation, sample,seed,out_folder,pos_emb,neg_emb,base_safe,vae_safe)\n",
        "else:\n",
        "  if v==\"\":\n",
        "    vae_safe=\"None.txt\"\n",
        "  seeds=mokuba_colab.text2image( loras, lora_weights, prompt, n_prompt, t, prog_ver, pic_number, gs, f_step, step, ss, cs, Interpolation, sample,seed,out_folder,pos_emb,neg_emb,base_safe,vae_safe)\n",
        "from IPython import get_ipython\n",
        "get_ipython().magic(\"reset -sf\")\n"
      ],
      "metadata": {
        "id": "eQY07Gb4IzeS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title logout\n",
        "from google.colab import runtime\n",
        "\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "tF7eT-EVfch8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}