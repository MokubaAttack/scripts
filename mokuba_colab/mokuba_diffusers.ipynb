{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-75f22n11Af"
      },
      "source": [
        "##setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2kDrgMzfmSUa"
      },
      "outputs": [],
      "source": [
        "#@title need\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip uninstall diffusers torch torchvision -y\n",
        "!pip install compel\n",
        "!pip install pyexiv2\n",
        "!pip install torchsde\n",
        "!pip install xformers torch torchvision --index-url https://download.pytorch.org/whl/cu126\n",
        "!pip install diffusers==0.34.0\n",
        "!pip install py-real-esrgan\n",
        "\n",
        "import requests,py-real-esrgan,os\n",
        "url=\"https://raw.githubusercontent.com/MokubaAttack/scripts/refs/heads/main/mokuba_colab/mokuba_colab.py\"\n",
        "path=\"mokuba_colab.py\"\n",
        "urlData = requests.get(url).content\n",
        "with open(path ,mode='wb') as f:\n",
        "  f.write(urlData)\n",
        "\n",
        "path=os.path.dirname(py_real_esrgan.__file__)+\"/model.py\"\n",
        "url=\"https://raw.githubusercontent.com/MokubaAttack/scripts/refs/heads/main/mokuba_colab/realersgan/model_mod.py\"\n",
        "urlData = requests.get(url).content\n",
        "with open(path ,mode='wb') as f:\n",
        "    f.write(urlData)\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output(True)\n",
        "print(\"fin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp-m2DBF19iV"
      },
      "source": [
        "##checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH5N_2Co2EIN"
      },
      "source": [
        "###civitai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0DNDuVjFb1xy"
      },
      "outputs": [],
      "source": [
        "#@title get\n",
        "base_air=None# @param {\"type\":\"integer\"}\n",
        "\n",
        "from google.colab import userdata\n",
        "import requests\n",
        "import os\n",
        "import json\n",
        "\n",
        "ca_token=userdata.get('civitai')\n",
        "base_url = \"https://civitai.com/api/download/models/\"+str(base_air)+\"?type=Model&format=SafeTensor&token=\"+str(ca_token)\n",
        "base_path=\"base.safetensors\"\n",
        "with open(base_path, \"wb\") as fh:\n",
        "    data = requests.get(base_url,stream=True)\n",
        "    limit=1024*1024*1024*1024\n",
        "    dummy_data=b\"\"\n",
        "    step1=True\n",
        "    step2=True\n",
        "    for chunk in data.iter_content(chunk_size=1024*1024):\n",
        "        if step2:\n",
        "            dummy_data=dummy_data+chunk\n",
        "        else:\n",
        "            fh.write(chunk)\n",
        "        if len(dummy_data)>8 and step1:\n",
        "            limit=int.from_bytes(dummy_data[:8],byteorder=\"little\")\n",
        "            dummy_data=dummy_data[8:]\n",
        "            step1=False\n",
        "        if len(dummy_data)>limit and step2:\n",
        "            head=dummy_data[:limit].decode()\n",
        "            head_dict=json.loads(head)\n",
        "            meta_dict={}\n",
        "            meta_dict[\"id\"]=str(base_air)\n",
        "            head_dict[\"__metadata__\"]=meta_dict\n",
        "            head=str(head_dict)\n",
        "            head=head.replace(\"'\",'\"')\n",
        "            b_data=head.encode()\n",
        "            b_len=len(b_data).to_bytes(8,byteorder=\"little\")\n",
        "            fh.write(b_len)\n",
        "            fh.write(b_data)\n",
        "            dummy_data=dummy_data[limit:]\n",
        "            fh.write(dummy_data)\n",
        "            step2=False\n",
        "\n",
        "print(str(base_air))\n",
        "from IPython import get_ipython\n",
        "get_ipython().magic(\"reset -sf\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6h2Z3uFTybB"
      },
      "source": [
        "When you input CivitAi's Version ID,  \n",
        "ckpt data is downloaded by the name of \"base.safetensors\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdW7Yxul2-RJ"
      },
      "source": [
        "##lora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lyrZ-WESLy4q"
      },
      "outputs": [],
      "source": [
        "#@title lora1\n",
        "lora_air=None# @param {\"type\":\"integer\"}\n",
        "\n",
        "from google.colab import userdata\n",
        "from requests import get\n",
        "from safetensors.torch import load_file,save_file\n",
        "ca_token=userdata.get('civitai')\n",
        "lora_url = \"https://civitai.com/api/download/models/\"+str(lora_air)+\"?type=Model&format=SafeTensor&token=\"+str(ca_token)\n",
        "lora_path=\"lora1.safetensors\"\n",
        "with open(lora_path, \"wb\") as fh:\n",
        "  data = get(lora_url, stream=True)\n",
        "  for chunk in data.iter_content(chunk_size=8192):\n",
        "    fh.write(chunk)\n",
        "\n",
        "unnecessary=[\n",
        "    \"lora_unet_out_2.alpha\",\n",
        "    \"lora_unet_out_2.lora_down.weight\",\n",
        "    \"lora_unet_out_2.lora_up.weight\",\n",
        "    \"lora_unet_input_blocks_0_0.alpha\",\n",
        "    \"lora_unet_input_blocks_0_0.lora_down.weight\",\n",
        "    \"lora_unet_input_blocks_0_0.lora_up.weight\",\n",
        "    \"lora_unet_label_emb_0_0.alpha\",\n",
        "    \"lora_unet_label_emb_0_0.lora_down.weight\",\n",
        "    \"lora_unet_label_emb_0_0.lora_up.weight\",\n",
        "    \"lora_unet_label_emb_0_2.alpha\",\n",
        "    \"lora_unet_label_emb_0_2.lora_down.weight\",\n",
        "    \"lora_unet_label_emb_0_2.lora_up.weight\",\n",
        "    \"lora_unet_time_embed_0.alpha\",\n",
        "    \"lora_unet_time_embed_0.lora_down.weight\",\n",
        "    \"lora_unet_time_embed_0.lora_up.weight\",\n",
        "    \"lora_unet_time_embed_2.alpha\",\n",
        "    \"lora_unet_time_embed_2.lora_down.weight\",\n",
        "    \"lora_unet_time_embed_2.lora_up.weight\"\n",
        "   ]\n",
        "\n",
        "state_dict = load_file(lora_path)\n",
        "ks=[]\n",
        "ws=[]\n",
        "for k, w in state_dict.items():\n",
        "    if not(k in unnecessary):\n",
        "        ks.append(k)\n",
        "        ws.append(w)\n",
        "l=len(ks)\n",
        "state_dict={}\n",
        "for i in range(l):\n",
        "    state_dict[ks[i]]=ws[i]\n",
        "meta_dict={}\n",
        "meta_dict[\"id\"]=str(lora_air)\n",
        "meta_dict[\"weight\"]=str(1)\n",
        "save_file(state_dict,lora_path,metadata=meta_dict)\n",
        "print(str(lora_air))\n",
        "from IPython import get_ipython\n",
        "get_ipython().magic(\"reset -sf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jMZcwkXUk-E"
      },
      "source": [
        "When you input CivitAi's Version ID,  \n",
        "lora data is downloaded by the name of \"lora1.safetensors\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aNZxcEclG18O"
      },
      "outputs": [],
      "source": [
        "#@title lora2\n",
        "lora_air=None# @param {\"type\":\"integer\"}\n",
        "\n",
        "from google.colab import userdata\n",
        "from requests import get\n",
        "from safetensors.torch import load_file,save_file\n",
        "ca_token=userdata.get('civitai')\n",
        "lora_url = \"https://civitai.com/api/download/models/\"+str(lora_air)+\"?type=Model&format=SafeTensor&token=\"+str(ca_token)\n",
        "lora_path=\"lora2.safetensors\"\n",
        "with open(lora_path, \"wb\") as fh:\n",
        "  data = get(lora_url, stream=True)\n",
        "  for chunk in data.iter_content(chunk_size=8192):\n",
        "    fh.write(chunk)\n",
        "\n",
        "unnecessary=[\n",
        "    \"lora_unet_out_2.alpha\",\n",
        "    \"lora_unet_out_2.lora_down.weight\",\n",
        "    \"lora_unet_out_2.lora_up.weight\",\n",
        "    \"lora_unet_input_blocks_0_0.alpha\",\n",
        "    \"lora_unet_input_blocks_0_0.lora_down.weight\",\n",
        "    \"lora_unet_input_blocks_0_0.lora_up.weight\",\n",
        "    \"lora_unet_label_emb_0_0.alpha\",\n",
        "    \"lora_unet_label_emb_0_0.lora_down.weight\",\n",
        "    \"lora_unet_label_emb_0_0.lora_up.weight\",\n",
        "    \"lora_unet_label_emb_0_2.alpha\",\n",
        "    \"lora_unet_label_emb_0_2.lora_down.weight\",\n",
        "    \"lora_unet_label_emb_0_2.lora_up.weight\",\n",
        "    \"lora_unet_time_embed_0.alpha\",\n",
        "    \"lora_unet_time_embed_0.lora_down.weight\",\n",
        "    \"lora_unet_time_embed_0.lora_up.weight\",\n",
        "    \"lora_unet_time_embed_2.alpha\",\n",
        "    \"lora_unet_time_embed_2.lora_down.weight\",\n",
        "    \"lora_unet_time_embed_2.lora_up.weight\"\n",
        "   ]\n",
        "\n",
        "state_dict = load_file(lora_path)\n",
        "ks=[]\n",
        "ws=[]\n",
        "for k, w in state_dict.items():\n",
        "    if not(k in unnecessary):\n",
        "        ks.append(k)\n",
        "        ws.append(w)\n",
        "l=len(ks)\n",
        "state_dict={}\n",
        "for i in range(l):\n",
        "    state_dict[ks[i]]=ws[i]\n",
        "meta_dict={}\n",
        "meta_dict[\"id\"]=str(lora_air)\n",
        "meta_dict[\"weight\"]=str(1)\n",
        "save_file(state_dict,lora_path,metadata=meta_dict)\n",
        "print(str(lora_air))\n",
        "from IPython import get_ipython\n",
        "get_ipython().magic(\"reset -sf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiHJAOCQUqhY"
      },
      "source": [
        "When you input CivitAi's Version ID,  \n",
        "lora data is downloaded by the name of \"lora2.safetensors\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ILet7SIaoNck"
      },
      "outputs": [],
      "source": [
        "#@title lora3\n",
        "lora_air=None# @param {\"type\":\"integer\"}\n",
        "\n",
        "from google.colab import userdata\n",
        "from requests import get\n",
        "from safetensors.torch import load_file,save_file\n",
        "ca_token=userdata.get('civitai')\n",
        "lora_url = \"https://civitai.com/api/download/models/\"+str(lora_air)+\"?type=Model&format=SafeTensor&token=\"+str(ca_token)\n",
        "lora_path=\"lora3.safetensors\"\n",
        "with open(lora_path, \"wb\") as fh:\n",
        "  data = get(lora_url, stream=True)\n",
        "  for chunk in data.iter_content(chunk_size=8192):\n",
        "    fh.write(chunk)\n",
        "\n",
        "unnecessary=[\n",
        "    \"lora_unet_out_2.alpha\",\n",
        "    \"lora_unet_out_2.lora_down.weight\",\n",
        "    \"lora_unet_out_2.lora_up.weight\",\n",
        "    \"lora_unet_input_blocks_0_0.alpha\",\n",
        "    \"lora_unet_input_blocks_0_0.lora_down.weight\",\n",
        "    \"lora_unet_input_blocks_0_0.lora_up.weight\",\n",
        "    \"lora_unet_label_emb_0_0.alpha\",\n",
        "    \"lora_unet_label_emb_0_0.lora_down.weight\",\n",
        "    \"lora_unet_label_emb_0_0.lora_up.weight\",\n",
        "    \"lora_unet_label_emb_0_2.alpha\",\n",
        "    \"lora_unet_label_emb_0_2.lora_down.weight\",\n",
        "    \"lora_unet_label_emb_0_2.lora_up.weight\",\n",
        "    \"lora_unet_time_embed_0.alpha\",\n",
        "    \"lora_unet_time_embed_0.lora_down.weight\",\n",
        "    \"lora_unet_time_embed_0.lora_up.weight\",\n",
        "    \"lora_unet_time_embed_2.alpha\",\n",
        "    \"lora_unet_time_embed_2.lora_down.weight\",\n",
        "    \"lora_unet_time_embed_2.lora_up.weight\"\n",
        "   ]\n",
        "\n",
        "state_dict = load_file(lora_path)\n",
        "ks=[]\n",
        "ws=[]\n",
        "for k, w in state_dict.items():\n",
        "    if not(k in unnecessary):\n",
        "        ks.append(k)\n",
        "        ws.append(w)\n",
        "l=len(ks)\n",
        "state_dict={}\n",
        "for i in range(l):\n",
        "    state_dict[ks[i]]=ws[i]\n",
        "meta_dict={}\n",
        "meta_dict[\"id\"]=str(lora_air)\n",
        "meta_dict[\"weight\"]=str(1)\n",
        "save_file(state_dict,lora_path,metadata=meta_dict)\n",
        "print(str(lora_air))\n",
        "from IPython import get_ipython\n",
        "get_ipython().magic(\"reset -sf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks7_-AT2VE9p"
      },
      "source": [
        "When you input CivitAi's Version ID,  \n",
        "lora data is downloaded by the name of \"lora3.safetensors\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uM_d7DroVf2f"
      },
      "outputs": [],
      "source": [
        "#@title file downloader\n",
        "ver_id=None # @param {\"type\":\"integer\"}\n",
        "\n",
        "from google.colab import userdata\n",
        "from requests import get\n",
        "from safetensors.torch import load_file,save_file\n",
        "ca_token=userdata.get('civitai')\n",
        "lora_url = \"https://civitai.com/api/download/models/\"+str(ver_id)+\"?type=Model&format=SafeTensor&token=\"+str(ca_token)\n",
        "lora_path=str(ver_id)+\".safetensors\"\n",
        "with open(lora_path, \"wb\") as fh:\n",
        "  data = get(lora_url, stream=True)\n",
        "  for chunk in data.iter_content(chunk_size=8192):\n",
        "    fh.write(chunk)\n",
        "\n",
        "unnecessary=[\n",
        "    \"lora_unet_out_2.alpha\",\n",
        "    \"lora_unet_out_2.lora_down.weight\",\n",
        "    \"lora_unet_out_2.lora_up.weight\",\n",
        "    \"lora_unet_input_blocks_0_0.alpha\",\n",
        "    \"lora_unet_input_blocks_0_0.lora_down.weight\",\n",
        "    \"lora_unet_input_blocks_0_0.lora_up.weight\",\n",
        "    \"lora_unet_label_emb_0_0.alpha\",\n",
        "    \"lora_unet_label_emb_0_0.lora_down.weight\",\n",
        "    \"lora_unet_label_emb_0_0.lora_up.weight\",\n",
        "    \"lora_unet_label_emb_0_2.alpha\",\n",
        "    \"lora_unet_label_emb_0_2.lora_down.weight\",\n",
        "    \"lora_unet_label_emb_0_2.lora_up.weight\",\n",
        "    \"lora_unet_time_embed_0.alpha\",\n",
        "    \"lora_unet_time_embed_0.lora_down.weight\",\n",
        "    \"lora_unet_time_embed_0.lora_up.weight\",\n",
        "    \"lora_unet_time_embed_2.alpha\",\n",
        "    \"lora_unet_time_embed_2.lora_down.weight\",\n",
        "    \"lora_unet_time_embed_2.lora_up.weight\"\n",
        "   ]\n",
        "\n",
        "state_dict = load_file(lora_path)\n",
        "ks=[]\n",
        "ws=[]\n",
        "for k, w in state_dict.items():\n",
        "    if not(k in unnecessary):\n",
        "        ks.append(k)\n",
        "        ws.append(w)\n",
        "l=len(ks)\n",
        "state_dict={}\n",
        "for i in range(l):\n",
        "    state_dict[ks[i]]=ws[i]\n",
        "meta_dict={}\n",
        "meta_dict[\"id\"]=str(ver_air)\n",
        "meta_dict[\"weight\"]=str(1)\n",
        "save_file(state_dict,lora_path,metadata=meta_dict)\n",
        "print(str(ver_air))\n",
        "from IPython import get_ipython\n",
        "get_ipython().magic(\"reset -sf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuTV0Y6sW2PI"
      },
      "source": [
        "When you input CivitAi's Version ID,  \n",
        "data is downloaded by the name of \"(ver_id).safetensors\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54dAGlTe3kPL"
      },
      "source": [
        "## run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eQY07Gb4IzeS"
      },
      "outputs": [],
      "source": [
        "#@title text2image\n",
        "\n",
        "#@markdown ##ckpt file\n",
        "base_safe=\"ckpt.safetensors\" #@param {type:\"string\"}\n",
        "#@markdown ##vae file\n",
        "vae_safe=\"vae.safetensors\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ##lora files\n",
        "loras=\"lora1, lora2\" #@param {type:\"string\"}\n",
        "if loras==\"\":\n",
        "  loras=[]\n",
        "else:\n",
        "  loras=loras.split(\",\")\n",
        "#@markdown ##lora weights\n",
        "lora_weights=\"1, 1\" #@param {type:\"string\"}\n",
        "if lora_weights==\"\":\n",
        "  lora_weights=[]\n",
        "else:\n",
        "  lora_weights=lora_weights.split(\",\")\n",
        "  for i in range(len(lora_weights)):\n",
        "    lora_weights[i]=float(lora_weights[i])\n",
        "\n",
        "#@markdown ##positive embedding files\n",
        "pos_emb=\"pos.safetensors\" #@param {type:\"string\"}\n",
        "#@markdown ##negative embedding files\n",
        "neg_emb=\"neg.safetensors, hand.safetensors\" #@param {type:\"string\"}\n",
        "if pos_emb==\"\":\n",
        "  pos_emb=[]\n",
        "else:\n",
        "  pos_emb=pos_emb.split(\",\")\n",
        "if neg_emb==\"\":\n",
        "  neg_emb=[]\n",
        "else:\n",
        "  neg_emb=neg_emb.split(\",\")\n",
        "\n",
        "#@markdown ##prompt\n",
        "prompt = \"\" #@param {type:\"string\"}\n",
        "#@markdown ##negative prompt\n",
        "n_prompt = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ##output size\n",
        "t=\"vl:large\" #@param [\"v:vertically long\", \"s:square\", \"h:horizontally long\",\"vl:large\",\"sl:large\",\"hl:large\"] {allow-input: true}\n",
        "t=t.split(\":\")[0]\n",
        "#@markdown ##program type\n",
        "prog_ver=\"2:mokuba.fix\" #@param [\"0:nomal\", \"1:hires.fix\", \"2:mokuba.fix\"] {allow-input: true}\n",
        "prog_ver=int(prog_ver.split(\":\")[0])\n",
        "\n",
        "#@markdown ##number of output image\n",
        "pic_number=10# @param {\"type\":\"integer\"}\n",
        "#@markdown ##guidance_scale\n",
        "gs=7# @param {\"type\":\"number\"}\n",
        "#@markdown ##num_inference_steps\n",
        "step=25# @param {\"type\":\"integer\"}\n",
        "#@markdown ##first num_inference_steps\n",
        "f_step=30# @param {\"type\":\"integer\"}\n",
        "#@markdown ##denoising_strength\n",
        "ss=0.5# @param {\"type\":\"number\"}\n",
        "#@markdown ##clip_skip\n",
        "cs=2# @param {\"type\":\"integer\"}\n",
        "\n",
        "#@markdown ##seed\n",
        "seed=\"0\"# @param {\"type\":\"string\"}\n",
        "if \",\" in seed:\n",
        "  seed=seed.split(\",\")\n",
        "\n",
        "#@markdown ##interpolation method\n",
        "Interpolation=\"1:NEAREST\" #@param [\"1:NEAREST\",\"2:BOX\",\"3:BILINEAR\",\"4:HAMMING\",\"5:BICUBIC\",\"6:LANCZOS\"] {allow-input: true}\n",
        "Interpolation=int(Interpolation.split(\":\")[0])\n",
        "#@markdown ##Scheduler\n",
        "sample=\"DDIM\" #@param [\"Euler a\",\"Euler\",\"LMS\",\"Heun\", \"DPM2\",\"DPM2 a\",\"DPM++\",\"DPM++ 2M\",\"DPM++ SDE\",\"DPM++ 2M SDE\",\"DPM++ 3M SDE\",\"DDIM\",\"PLMS\",\"UniPC\",\"LCM\"] {allow-input: true}\n",
        "#@markdown ##noise schedule and schedule type\n",
        "sgm=\"\" #@param [\"\",\"Karras\",\"sgm_uniform\",\"simple\",\"exponential\",\"beta\"] {allow-input: true}\n",
        "#@markdown ##pag_scale\n",
        "pag=3.0# @param {\"type\":\"number\"}\n",
        "\n",
        "#@markdown ##Output folder\n",
        "out_folder=\"\"#@param {type:\"string\"}\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import mokuba_colab\n",
        "\n",
        "pipe=mokuba_colab.text2image( \n",
        "    loras=loras, \n",
        "    lora_weights=lora_weights, \n",
        "    prompt=prompt, \n",
        "    n_prompt=n_prompt, \n",
        "    t=t, \n",
        "    prog_ver=prog_ver, \n",
        "    pic_number=pic_number, \n",
        "    gs=gs, \n",
        "    f_step=f_step, \n",
        "    step=step, \n",
        "    ss=ss, \n",
        "    cs=cs, \n",
        "    Interpolation=Interpolation, \n",
        "    sample=sample,\n",
        "    sgm=sgm,\n",
        "    seed=seed,\n",
        "    out_folder=out_folder,\n",
        "    pos_emb-pos_emb,\n",
        "    neg_emb=neg_emb,\n",
        "    base_safe=base_safe,\n",
        "    vae_safe=vae_safe,\n",
        "    pag=pag,\n",
        "    j_or_p=\"j\",\n",
        "    p=None\n",
        "    )\n",
        "from IPython import get_ipython\n",
        "get_ipython().magic(\"reset -sf\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title mokuup\n",
        "#@markdown ##pic path\n",
        "path=\"test.jpg\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ##ckpt file\n",
        "base_safe=\"ckpt.safetensors\" #@param {type:\"string\"}\n",
        "#@markdown ##vae file\n",
        "vae_safe=\"vae.safetensors\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ##lora files\n",
        "loras=\"lora1, lora2\" #@param {type:\"string\"}\n",
        "if loras==\"\":\n",
        "  loras=[]\n",
        "else:\n",
        "  loras=loras.split(\",\")\n",
        "#@markdown ##lora weights\n",
        "lora_weights=\"1, 1\" #@param {type:\"string\"}\n",
        "if lora_weights==\"\":\n",
        "  lora_weights=[]\n",
        "else:\n",
        "  lora_weights=lora_weights.split(\",\")\n",
        "  for i in range(len(lora_weights)):\n",
        "    lora_weights[i]=float(lora_weights[i])\n",
        "\n",
        "#@markdown ##positive embedding files\n",
        "pos_emb=\"pos.safetensors\" #@param {type:\"string\"}\n",
        "#@markdown ##negative embedding files\n",
        "neg_emb=\"neg.safetensors, hand.safetensors\" #@param {type:\"string\"}\n",
        "if pos_emb==\"\":\n",
        "  pos_emb=[]\n",
        "else:\n",
        "  pos_emb=pos_emb.split(\",\")\n",
        "if neg_emb==\"\":\n",
        "  neg_emb=[]\n",
        "else:\n",
        "  neg_emb=neg_emb.split(\",\")\n",
        "\n",
        "#@markdown ##number of output image\n",
        "pic_number=3# @param {\"type\":\"integer\"}\n",
        "#@markdown ##guidance_scale\n",
        "gs=6# @param {\"type\":\"number\"}\n",
        "#@markdown ##upscale\n",
        "up=1.5# @param {\"type\":\"number\"}\n",
        "\n",
        "#@markdown ##num_inference_steps\n",
        "step=20# @param {\"type\":\"integer\"}\n",
        "#@markdown ##denoising_strength\n",
        "ss=0.2# @param {\"type\":\"number\"}\n",
        "#@markdown ##clip_skip\n",
        "cs=2# @param {\"type\":\"integer\"}\n",
        "\n",
        "#@markdown ##seed\n",
        "seed=\"0\"# @param {\"type\":\"string\"}\n",
        "if \",\" in seed:\n",
        "  seed=seed.split(\",\")\n",
        "  pic_number=len(seed)\n",
        "else:\n",
        "  dummy_seed=[]\n",
        "  for i in range(pic_number):\n",
        "    dummy_seed.append(seed)\n",
        "  seed=dummy_seed\n",
        "\n",
        "#@markdown ##interpolation method\n",
        "Interpolation=\"3:BILINEAR\" #@param [\"1:NEAREST\",\"2:BOX\",\"3:BILINEAR\",\"4:HAMMING\",\"5:BICUBIC\",\"6:LANCZOS\"] {allow-input: true}\n",
        "if \":\" in Interpolation:\n",
        "  Interpolation=int(Interpolation.split(\":\")[0])\n",
        "#@markdown ##Scheduler\n",
        "sample=\"DDIM\" #@param [\"Euler a\",\"Euler\",\"LMS\",\"Heun\", \"DPM2\",\"DPM2 a\",\"DPM++ 2M\",\"DPM++\",\"DPM++ SDE\",\"DPM++ 2M SDE\",\"DPM++ 3M SDE\",\"DDIM\",\"PLMS\",\"UniPC\",\"LCM\"] {allow-input: true}\n",
        "#@markdown ##noise schedule and schedule type\n",
        "sgm=\"\" #@param [\"\",\"Karras\",\"sgm_uniform\",\"simple\",\"exponential\",\"beta\"] {allow-input: true}\n",
        "\n",
        "#@markdown ##pag_scale\n",
        "pag=3.0# @param {\"type\":\"number\"}\n",
        "#@markdown ##controlnet_conditioning_scale\n",
        "ccs=0.75# @param {\"type\":\"number\"}\n",
        "\n",
        "#@markdown ##Output folder\n",
        "out_folder=\"\"#@param {type:\"string\"}\n",
        "\n",
        "pipe=mokuup.tile_up(\n",
        "    img_path=path,\n",
        "    base_safe=base_safe,\n",
        "    vae_safe=vae_safe,\n",
        "    loras=loras,\n",
        "    lora_weights=lora_weights,\n",
        "    up=up,\n",
        "    gs=gs,\n",
        "    step=step,\n",
        "    ss=ss,\n",
        "    cs=cs,\n",
        "    Interpolation=Interpolation,\n",
        "    sample=sample,\n",
        "    sgm=sgm,\n",
        "    seed=seed,\n",
        "    pos_emb=pos_emb,\n",
        "    neg_emb=neg_emb,\n",
        "    pag=pag,\n",
        "    out_folder=out_folder,\n",
        "    j_or_p=\"j\",\n",
        "    ccs=ccs\n",
        ")\n",
        "\n",
        "from IPython import get_ipython\n",
        "get_ipython().magic(\"reset -sf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tF7eT-EVfch8"
      },
      "outputs": [],
      "source": [
        "#@title logout\n",
        "from google.colab import runtime\n",
        "\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
